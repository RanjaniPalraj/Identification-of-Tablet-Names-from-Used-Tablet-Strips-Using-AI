# -*- coding: utf-8 -*-
"""DenseNet_Attention_Spatial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u9WaAybIjPE7nIKcQvP6q_3bQzgH5w1c
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Multiply, Input
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import confusion_matrix, classification_report

# Define dataset directories
train_dir = '/content/drive/MyDrive/DataSet/Train'
test_dir = '/content/drive/MyDrive/DataSet/Valid'

# Define parameters
input_shape = (224, 224, 3)
num_classes = len(os.listdir(train_dir))
batch_size = 8
epochs = 4

# Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1.0/255.0)

# Load train set images
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=input_shape[:2],
    batch_size=batch_size,
    class_mode='categorical')

# Load test set images
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=input_shape[:2],
    batch_size=batch_size,
    class_mode='categorical')

# Load the pre-trained DenseNet121 model
base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)

# Create a new model using the DenseNet121 base
model = Sequential([
    base_model,
    Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'),
    BatchNormalization(),
    Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu'),
    BatchNormalization(),
    Flatten(),
    Dense(units=4096, activation='relu'),
    Dense(units=4096, activation='relu'),
    Dense(units=num_classes, activation='softmax')
])

# Freeze the layers of the DenseNet121 base
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Spatial Attention Layer
class SpatialAttention(tf.keras.layers.Layer):
    def __init__(self, kernel_size=7, **kwargs):
        super(SpatialAttention, self).__init__(**kwargs)
        self.kernel_size = kernel_size
        self.conv = Conv2D(1, kernel_size=self.kernel_size, padding='same', activation='sigmoid')

    def call(self, inputs):
        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
        concat = tf.concat([avg_pool, max_pool], axis=-1)
        attention_map = self.conv(concat)
        output = Multiply()([inputs, attention_map])
        return output

input_tensor = Input(shape=(64, 64, 128))
x = SpatialAttention()(input_tensor)

# Model Summary
model.summary()

def predict_single_image(image_path, model):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image) / 255.0  # Normalize
    image = np.expand_dims(image, axis=0)
    prediction = model.predict(image)
    class_index = np.argmax(prediction)
    class_labels = train_generator.class_indices  # Dictionary of class indices to class labels
    predicted_class = list(class_labels.keys())[list(class_labels.values()).index(class_index)]
    confidence = prediction[0][class_index] * 100.0
    return predicted_class, confidence

# Train the model
hist = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=epochs)

image_path = '/content/drive/MyDrive/DataSet/Test/Albendazole/Albendazole_Test (45).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Amoxicillin/Amoicillin_Test (10).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Antacid/Antacid_Test (13).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Citerzine/Citerzine_Test (12) (1).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Diclowin/Diclowin_Test (12).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Etofylline/Etofylline_Test (15).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Glimepride/Glimepride_Test (16).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Metformin/Metformin_Test (17).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Nicip plus/Nicip plus_Test (2).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Okamet/Okamet_Test (17).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Omega/Omega_Test (39).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Paracetamol/Paracetamol_Test (18).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Paracetamol_500/Paracetamol500_Test (2).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Ranitidine/Ranitidine_Test (24).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Vitamin/Vitamin_Test (2).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

image_path = '/content/drive/MyDrive/DataSet/Test/Zincon/Zincon_Test (24).jpg'
predicted_class, confidence = predict_single_image(image_path, model)
print(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}%")

